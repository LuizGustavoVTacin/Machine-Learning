{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aadc69b",
   "metadata": {},
   "source": [
    "# Tópicos\n",
    "\n",
    "1. Working with data\n",
    "\n",
    "2. Criando modelos\n",
    "\n",
    "3. Otimizando parâmetros do modelo\n",
    "\n",
    "4. Salvando modelos\n",
    "\n",
    "5. Carregando modelos\n",
    "\n",
    "6. Visualizando Imagens\n",
    "\n",
    "7. Observando múltiplos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0f7d5",
   "metadata": {},
   "source": [
    "# Working with data\n",
    "\n",
    "PyTorch contém datasets integrados para aprendizado inicial\n",
    "\n",
    "Dataset usando para tutorial: FashionMNIST\n",
    "\n",
    "```torchvision.datasets```contem ```Dataset``` para datasets de visão computacional, como CIFAR, COCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ae4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70d7fb",
   "metadata": {},
   "source": [
    "O dataset é passado no argumento da função ```DataLoader```para criar objeto iterável para\n",
    "\n",
    "1. **batching**: subconjunto de dados de treinamento que é usado em uma única iteração de um algoritmo de otimização, como gradiente descendente\n",
    "\n",
    "    Principais modos de batch:\n",
    "\n",
    "    * Full-batch: O tamanho do lote é igual ao tamanho total do conjunto de dados\n",
    "    * Modo Mini-Batch: O tamanho do lote é maior que 1, mas menor que o conjunto de dados total\n",
    "    * Stochastic: O tamanho do lado é 1\n",
    "\n",
    "    Batches menores tendem a introduzir mais ruído no processo de otimização, o que pode ajudar a rede a escapar de mínimos locais e encontrar soluções melhores, mas leva a convergência mais lenta\n",
    "\n",
    "    Batches maiores resultam em uma estimativa de gradiente mais precisa, permitindo que a rede avance mais rapidamente em direção a um mínimo mas podem ficar presos em mínimos locais e exigem mais memória\n",
    "\n",
    "2. **Sampling**: Técnica mais ampla que preocupa com a composição da amostra para garantir que o subconjunto de dados seja representativo do conjunto de dados total.\n",
    "\n",
    "    Principais modos de sampling:\n",
    "\n",
    "    * Amostragem aleatória: Subconjunto de dados complementares aleatórios\n",
    "    * Amostragem estratificada: Criação de subgrupos com características comuns e, então, amostras são coletadas de cada subgrupo para formar um subconjunto. Útil com amostras desbalanceadas, como, por exemplo, detecção de fraudes (classe minoritária é preservada na amostra).\n",
    "    * Sobreamostragem e subamostragem: Técnica para conjuntos desbalanceados. A sobreamostragem aumenta o número de exemplos de classe minoritária, enquanto a subamostragem reduz o número de exemplos de classe majoritária.\n",
    "\n",
    "3. **shuffling**: Técnica para randomizar a ordem dos dados de treinamento antes ou durante de cada época. O objetivo é evitar que o modelo aprenda padrões baseados na ordem que os dados são apresentados.\n",
    "\n",
    "4. **multiprocess**: Paralelização do trinamento\n",
    "\n",
    "No exemplo, o batch size é definido com o valor de 64, de forma que cada elemento iterável no DataLoader retornará um batch de 64 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e3fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 938\n",
      "Tamanho do conjunto de teste: 157\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print(f'Tamanho do conjunto de treino: {len(train_dataloader)}')\n",
    "print(f'Tamanho do conjunto de teste: {len(test_dataloader)}')\n",
    "\n",
    "# X recebe um batch (64 elementos)\n",
    "# y recebe um batch de 64 labels correspondentes aos dados em X\n",
    "# break irá encerrar após a primeira iteração\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "# N retorna 64 -> tamanho do batch\n",
    "# C, H e W -> Dimensão para os dados, como canais de cor, altura e largura para dados de imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf0dc0",
   "metadata": {},
   "source": [
    "# Criando Modelos\n",
    "\n",
    "Modelos com PyTorch são criados com classes que herdam de ```n.Module```.\n",
    "\n",
    "As camadas da rede são definidas na função ```__init__```e a forma que os dados passam pela rede na função ```forward```.\n",
    "\n",
    "* ```nn.Flatten```converte uma imagem 2D para um array contínuo\n",
    "* ```nn.Linear```aplicada uma transformação linear na entrada, usando pesos e limiares armazenados\n",
    "* ```nn.ReLU``` ativações não lineares criam mapeamentos complexos entre as entradas e saídas. Elas são aplicadas após a transformação linear para introduzir não linearidades para judar a rede a aprender fenômenos diversos.\n",
    "\n",
    "```ReLU(f(X) = max(0, x))```\n",
    "\n",
    "* ```nn.Sequential``` é um container ordenado de módulos. Os dados são passados todos na mesma ordem definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a23156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a00da4",
   "metadata": {},
   "source": [
    "# Otimizando parâmetros do modelo\n",
    "\n",
    "Para treinar o modelo, são necessários <u>Loss Function</u> e um <u>otimizador</u>\n",
    "\n",
    "1. **Loss Function**: Função matemática que mede a diferença entre saída prevista de um modelo e o valor real. O principal objetivo é a minimização da função de perda.\n",
    "\n",
    "    Principais tipos para Regressões:\n",
    "\n",
    "    * **Mean Squared Error (MSE)**: Média do quadrado das diferenças entre os valores previstos e os valores reais.\n",
    "\n",
    "        * Penaliza erros maiores de forma mais severa devido ao quadrado, tornando sensível a *outliers*.\n",
    "\n",
    "    * **Mean Absolute Error (MAE)**: Calcula a média das diferenças absolutas entre os valores previstos e reais\n",
    "        * Útil quando o conjunto de dados contém valores discrepantes que não devem influenciar o modelo\n",
    "\n",
    "    * **Huber Loss**: Função de perda híbrida que combina MSE e MAE.\n",
    "        * Útil quando há presença de *outliers* e é necessário bom equilíbrio\n",
    "\n",
    "    Principais tipos para Classificações:\n",
    "\n",
    "    * **Binary Cross-Entropy**: Mede a diferença entre a distribuição de probabilidade prevista pelo modelo e a distribuiçãoo real\n",
    "        * Útil para classificação de duas classes, como detecção de *spam* pu *diagnóstico de doenças*.\n",
    "\n",
    "    * **Categorical Cross-Entropy**: Extensão de Binary Cross-Entropy para problemas com mais de duas classes\n",
    "\n",
    "    *  **Sparse Categorical Cross-Entropy**: Semelhante a categorical Cross-Entropy, mas usada quando os rótulos de classe são inteiros em vez de vetores one-hot encoded.\n",
    "\n",
    "2. **Otimizadores**: São algoritmos para ajuste de parâmetros internos do modelo (Pesos e Vieses) para minimizar função de perda. Indicam qual a direção e com qual intensidade os parâmetros devem ser alterados a cada alteração.\n",
    "\n",
    "    Principais otimizadores:\n",
    "\n",
    "    * **SGD (Stochastic Gradient Decendent)**: Para cada mini-batch (subconjunto de um batch), o SGD calcula o gradiente da função de perda em relação aos parâmetros do modelo.\n",
    "        * Útil com conjuntos de dados pequenos ou problemas menos complexos, onde a simplicidade e a eficiência computacional são prioritárias.\n",
    "\n",
    "    * **SGC com Momento**: Adiciona um termo de momento que acelera a convergência na direção correta e reduz a oscilação.\n",
    "        * Útil com modelos profundos, onde a complexidade da paisagem de perda pode dificultar a convergência para o SGD padrão.\n",
    "\n",
    "    * **AdaGrad**: Adapta a taxa de aprendizado para cada parâmetro individualmente. Diminui a taxa de aprendizado para parâmetros com grandes gradientes e aumenta para aqueles com pequenos gradientes.\n",
    "        * Útil com dados esparsos (por exemplo, dados de processamento de linguagem natural), onde alguns recursos são raros e outros são frequentes.\n",
    "\n",
    "    * **RMSprop**: Similar ao AdaGrad, mas utiliza uma média móvel dos quadrados dos gradientes para evitar que a taxa de aprendizado diminua rapidamente.\n",
    "        * Útil com dados não estacionários, onde os padrões de gradiente podem mudar ao longo do tempo. É frequentemente usado em redes neurais recorrentes (RNNs) e dados de séries temporais.\n",
    "\n",
    "    * **Adam (Adaptative Moment Estimation)**: Um dos otimizadores mais populares. Combina as ideias de momento e adaptatividade para ajustar a taxa de aprendizado de forma eficiente.\n",
    "        * Útil com grandes conjuntos de dados e redes neurais profundas e sem tempo para otimizar manualmente a taxa de aprendizado, já que o Adam ajusta as taxas de aprendizado para cada parâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a96a1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) #Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba0d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14c9d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94f8d7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.299670  [   64/60000]\n",
      "loss: 2.285933  [ 6464/60000]\n",
      "loss: 2.260698  [12864/60000]\n",
      "loss: 2.256478  [19264/60000]\n",
      "loss: 2.226507  [25664/60000]\n",
      "loss: 2.207043  [32064/60000]\n",
      "loss: 2.214581  [38464/60000]\n",
      "loss: 2.178691  [44864/60000]\n",
      "loss: 2.170147  [51264/60000]\n",
      "loss: 2.136353  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 2.128926 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.141726  [   64/60000]\n",
      "loss: 2.129738  [ 6464/60000]\n",
      "loss: 2.060747  [12864/60000]\n",
      "loss: 2.080667  [19264/60000]\n",
      "loss: 2.022586  [25664/60000]\n",
      "loss: 1.965390  [32064/60000]\n",
      "loss: 1.990624  [38464/60000]\n",
      "loss: 1.906367  [44864/60000]\n",
      "loss: 1.901297  [51264/60000]\n",
      "loss: 1.835432  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.829277 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.861504  [   64/60000]\n",
      "loss: 1.835541  [ 6464/60000]\n",
      "loss: 1.700261  [12864/60000]\n",
      "loss: 1.751600  [19264/60000]\n",
      "loss: 1.640512  [25664/60000]\n",
      "loss: 1.597228  [32064/60000]\n",
      "loss: 1.613587  [38464/60000]\n",
      "loss: 1.516231  [44864/60000]\n",
      "loss: 1.536177  [51264/60000]\n",
      "loss: 1.442734  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.458124 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.520961  [   64/60000]\n",
      "loss: 1.497868  [ 6464/60000]\n",
      "loss: 1.332559  [12864/60000]\n",
      "loss: 1.422440  [19264/60000]\n",
      "loss: 1.302514  [25664/60000]\n",
      "loss: 1.303084  [32064/60000]\n",
      "loss: 1.319597  [38464/60000]\n",
      "loss: 1.241822  [44864/60000]\n",
      "loss: 1.276680  [51264/60000]\n",
      "loss: 1.190557  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.211267 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.284710  [   64/60000]\n",
      "loss: 1.276774  [ 6464/60000]\n",
      "loss: 1.095785  [12864/60000]\n",
      "loss: 1.219273  [19264/60000]\n",
      "loss: 1.093253  [25664/60000]\n",
      "loss: 1.119067  [32064/60000]\n",
      "loss: 1.146242  [38464/60000]\n",
      "loss: 1.076236  [44864/60000]\n",
      "loss: 1.116575  [51264/60000]\n",
      "loss: 1.046574  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 1.060488 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5522c23",
   "metadata": {},
   "source": [
    "# Salvando Modelos\n",
    "\n",
    "Serializa o estado interno do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f39482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4ce38",
   "metadata": {},
   "source": [
    "# Carregando Modelos\n",
    "\n",
    "Recria a estrutura do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2df2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83bccb",
   "metadata": {},
   "source": [
    "# Visualizando Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd81500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoVUlEQVR4nO3de3SU9Z3H8c8khCEJycQQcuMSwkWQ67ooKeVSkJSQohXE9dLuKVIOLBpagXpZ1gqCPY3QVq1dinrOClYBW0Wg0pYtAoHVcim3spwWSrIBwiVBwMxAYgIkv/2DZdYhgfA8JPkl4f0653eO88zvO893njzk48w8+Y3HGGMEAEAjC7PdAADg1kQAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAoVk4fPiwPB6PfvrTn9bbY+bl5cnj8SgvL6/eHrM+dOnSRffee2+d8zwej1544YV626/H49H06dPr7fGAuhBAaDBLly6Vx+PRzp07bbfS4B566CF5PB49++yztltpdk6cOKEXXnhBe/futd0KGhkBBNykQCCgjz76SF26dNGKFSvE8orOnDhxQvPmzSOAbkEEEHCTVq5cqaqqKr311lsqKirSli1bbLcENAsEEKy6cOGC5syZo4EDB8rn8yk6OlrDhg3Tpk2brlnzyiuvKC0tTZGRkfra176m/fv315hz4MABPfjgg4qPj1ebNm1011136be//W2d/ZSXl+vAgQM6ffr0DT+HZcuW6etf/7pGjhypO+64Q8uWLasx58rbkZ9++qlmzZql9u3bKzo6WuPHj9dnn31W5z7efvtttWrVSk8//fR15x0/flzf/e53lZSUJK/Xqz59+uitt9664edy5fn07NlTbdq00cCBA2sN1D179ig7O1uxsbFq27atRo0apW3bttWY9z//8z/6p3/6J8XHxysqKkpf+cpX9Lvf/S54f15enu6++25J0qRJk+TxeOTxeLR06VJHPaOZMkADWbJkiZFk/vznP19zzmeffWZSUlLMrFmzzOLFi83ChQtNz549TUREhNmzZ09wXmFhoZFk+vXrZ7p06WIWLFhg5s2bZ+Lj40379u1NcXFxcO7+/fuNz+czvXv3NgsWLDD//u//boYPH248Ho/58MMPg/M2bdpkJJlNmzbV2DZ37twbeo7Hjx83YWFh5p133jHGGDN//nxz2223mcrKylqPxZ133mnuuece84tf/ML84Ac/MOHh4eahhx4KmZuWlmbGjh0bvP3GG28Yj8djnnvuuZB5V/dZXFxsOnbsaDp16mTmz59vFi9ebL75zW8aSeaVV16p87lIMn379jUJCQlm/vz5ZsGCBSYtLc1ERkaa//7v/w7O279/v4mOjjYpKSnmxRdfNC+99JJJT083Xq/XbNu2LaSfpKQkExMTY5577jnz8ssvmwEDBpiwsLDgz6G4uNjMnz/fSDJTp04177zzjnnnnXdMQUFBnf2i+SOA0GBuJIAuXbpU45f1559/bpKSksx3v/vd4LYrARQZGWmOHTsW3L59+3YjycycOTO4bdSoUaZfv36moqIiuK26utp89atfNT169Ahuq48A+ulPf2oiIyNNIBAwxhjz97//3Ugyq1atqvVYZGZmmurq6uD2mTNnmvDwcFNaWhrc9uUA+vnPf248Ho958cUXa+z76j4nT55sUlJSzOnTp0PmPfLII8bn85ny8vLrPhdJRpLZuXNncNuRI0dMmzZtzPjx44Pbxo0bZ1q3bh0SEidOnDAxMTFm+PDhwW0zZswwksx//dd/BbedO3fOpKenmy5dupiqqipjjDF//vOfjSSzZMmS6/aHloe34GBVeHi4WrduLUmqrq7W2bNndenSJd11113avXt3jfnjxo1Thw4dgrcHDRqkjIwM/f73v5cknT17Vhs3btRDDz2kc+fO6fTp0zp9+rTOnDmjrKwsHTp0SMePH79mPyNGjJAx5oYvb162bJnGjh2rmJgYSVKPHj00cODAWt+Gk6SpU6fK4/EEbw8bNkxVVVU6cuRIjbkLFy7Uk08+qQULFuiHP/zhdfswxmjlypW67777ZIwJPu/Tp08rKytLfr+/1uN5tcGDB2vgwIHB2507d9b999+v//zP/1RVVZWqqqr0xz/+UePGjVPXrl2D81JSUvStb31Ln3zyiQKBgCTp97//vQYNGqShQ4cG57Vt21ZTp07V4cOH9de//rXOftCytbLdAPD222/rZz/7mQ4cOKCLFy8Gt6enp9eY26NHjxrbbr/9dv3mN7+RJOXn58sYo+eff17PP/98rfs7depUSIi59be//U179uzRd77zHeXn5we3jxgxQosWLVIgEFBsbGxITefOnUNu33bbbZKkzz//PGT75s2b9bvf/U7PPvtsnZ/7SNJnn32m0tJSvfnmm3rzzTdrnXPq1Kk6H+dax7e8vDz4WVV5ebl69uxZY94dd9yh6upqFRUVqU+fPjpy5IgyMjJqnSdJR44cUd++fevsCS0XAQSr3n33XT322GMaN26cnn76aSUmJio8PFy5ubkqKChw/HjV1dWSpKeeekpZWVm1zunevftN9XzFu+++K0maOXOmZs6cWeP+lStXatKkSSHbwsPDa30sc9Wl23369FFpaaneeecd/cu//EutYfxlV573P//zP2vixIm1zunfv/91HwNobAQQrPrggw/UtWtXffjhhyFvTc2dO7fW+YcOHaqx7e9//7u6dOkiScG3hSIiIpSZmVn/Df8fY4yWL1+ukSNH6oknnqhx/4svvqhly5bVCKAblZCQoA8++EBDhw7VqFGj9Mknnyg1NfWa89u3b6+YmBhVVVXd1PO+1vGNiopS+/btJUlRUVE6ePBgjXkHDhxQWFiYOnXqJElKS0u75rwr90sK+bnj1sJnQLDqyiuCL78C2L59u7Zu3Vrr/NWrV4d8hrNjxw5t375d2dnZkqTExESNGDFCb7zxhk6ePFmjvq5Lnm/0MuxPP/1Uhw8f1qRJk/Tggw/WGA8//LA2bdqkEydOXPdxrqdjx476+OOP9cUXX+jrX/+6zpw5c8254eHhmjBhglauXFnrZek3cqm3JG3dujXks6KioiKtWbNGo0ePVnh4uMLDwzV69GitWbNGhw8fDs4rKSnR8uXLNXTo0ODbjt/4xje0Y8eOkJ9lWVmZ3nzzTXXp0kW9e/eWJEVHR0uSSktLb6hHtBy8AkKDe+utt7Ru3boa25988knde++9+vDDDzV+/HiNHTtWhYWFev3119W7d2+dP3++Rk337t01dOhQPf7446qsrNSrr76qdu3a6ZlnngnOWbRokYYOHap+/fppypQp6tq1q0pKSrR161YdO3ZMf/nLX67Z644dOzRy5EjNnTv3uhciLFu2TOHh4Ro7dmyt93/zm9/Uc889p/fee0+zZs26ztG5vu7du+uPf/yjRowYoaysLG3cuLHG50pXvPTSS9q0aZMyMjI0ZcoU9e7dW2fPntXu3bv18ccf6+zZs3Xur2/fvsrKytL3v/99eb1e/fKXv5QkzZs3LzjnRz/6kdavX6+hQ4fqiSeeUKtWrfTGG2+osrJSCxcuDM7713/9V61YsULZ2dn6/ve/r/j4eL399tsqLCzUypUrFRZ2+f9/u3Xrpri4OL3++uuKiYlRdHS0MjIy6nzbES2AxSvw0MJdufT4WqOoqMhUV1ebH//4xyYtLc14vV5z5513mrVr15qJEyeatLS04GNduQz7Jz/5ifnZz35mOnXqZLxerxk2bJj5y1/+UmPfBQUF5jvf+Y5JTk42ERERpkOHDubee+81H3zwQXCO28uwL1y4YNq1a2eGDRt23eefnp5u7rzzzpBjcfUl6bX1cPXfARlz+XLzK5c5X7mcurY+S0pKTE5OjunUqZOJiIgwycnJZtSoUebNN9+8bq9XHi8nJ8e8++67pkePHsGfx5d7u2L37t0mKyvLtG3b1kRFRZmRI0eaP/3pTzXmFRQUmAcffNDExcWZNm3amEGDBpm1a9fWmLdmzRrTu3dv06pVKy7JvoV4jGHhKgBA4+MzIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGhyf4haXV2tEydOKCYmhiU6AKAZMsbo3LlzSk1NDf7BcW2aXACdOHEiuJYUAKD5KioqUseOHa95f5N7C+7K96oAAJq3un6fN1gALVq0SF26dFGbNm2UkZGhHTt23FAdb7sBQMtQ1+/zBgmgX//615o1a5bmzp2r3bt3a8CAAcrKyrqhL8QCANwiGmKBuUGDBpmcnJzg7aqqKpOammpyc3PrrPX7/dddwJLBYDAYzWP4/f7r/r6v91dAFy5c0K5du0K+FCssLEyZmZm1fsdLZWWlAoFAyAAAtHz1HkCnT59WVVWVkpKSQrYnJSWpuLi4xvzc3Fz5fL7g4Ao4ALg1WL8Kbvbs2fL7/cFRVFRkuyUAQCOo978DSkhIUHh4uEpKSkK2l5SUKDk5ucZ8r9crr9db320AAJq4en8F1Lp1aw0cOFAbNmwIbquurtaGDRs0ePDg+t4dAKCZapCVEGbNmqWJEyfqrrvu0qBBg/Tqq6+qrKxMkyZNaojdAQCaoQYJoIcfflifffaZ5syZo+LiYv3DP/yD1q1bV+PCBADArctjjDG2m/iyQCAgn89nuw0AwE3y+/2KjY295v3Wr4IDANyaCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKyo9wB64YUX5PF4QkavXr3qezcAgGauVUM8aJ8+ffTxxx///05aNchuAADNWIMkQ6tWrZScnNwQDw0AaCEa5DOgQ4cOKTU1VV27dtW3v/1tHT169JpzKysrFQgEQgYAoOWr9wDKyMjQ0qVLtW7dOi1evFiFhYUaNmyYzp07V+v83Nxc+Xy+4OjUqVN9twQAaII8xhjTkDsoLS1VWlqaXn75ZU2ePLnG/ZWVlaqsrAzeDgQChBAAtAB+v1+xsbHXvL/Brw6Ii4vT7bffrvz8/Frv93q98nq9Dd0GAKCJafC/Azp//rwKCgqUkpLS0LsCADQj9R5ATz31lDZv3qzDhw/rT3/6k8aPH6/w8HA9+uij9b0rAEAzVu9vwR07dkyPPvqozpw5o/bt22vo0KHatm2b2rdvX9+7AgA0Yw1+EYJTgUBAPp/PdhsAgJtU10UIrAUHALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFY0+BfSAcC1hIeHO66prq52XNOYay67+YLNL38r9I3q3r274xpJ1/xyUBt4BQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArWA0buEkej6dRatysAt2hQwfHNZI0ePBgxzV/+MMfHNeUlZU5rmnq3Kxs7caECRNc1S1YsKCeO3GPV0AAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAWLkQIWuFlY1I1hw4a5qsvIyHBck5qa6rjmtddec1zT1CUmJjquycrKclwTCAQc1zQ1vAICAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACtYjBS4SeHh4Y5rLl265Ljmrrvuclxzxx13OK6RpJKSEsc1PXr0cFyzatUqxzVnz551XBMZGem4RpKOHDniuKZdu3aOa2JjYx3XHDt2zHFNU8MrIACAFQQQAMAKxwG0ZcsW3XfffUpNTZXH49Hq1atD7jfGaM6cOUpJSVFkZKQyMzN16NCh+uoXANBCOA6gsrIyDRgwQIsWLar1/oULF+q1117T66+/ru3btys6OlpZWVmqqKi46WYBAC2H44sQsrOzlZ2dXet9xhi9+uqr+uEPf6j7779fkvSrX/1KSUlJWr16tR555JGb6xYA0GLU62dAhYWFKi4uVmZmZnCbz+dTRkaGtm7dWmtNZWWlAoFAyAAAtHz1GkDFxcWSpKSkpJDtSUlJwfuulpubK5/PFxydOnWqz5YAAE2U9avgZs+eLb/fHxxFRUW2WwIANIJ6DaDk5GRJNf+IraSkJHjf1bxer2JjY0MGAKDlq9cASk9PV3JysjZs2BDcFggEtH37dg0ePLg+dwUAaOYcXwV3/vx55efnB28XFhZq7969io+PV+fOnTVjxgz96Ec/Uo8ePZSenq7nn39eqampGjduXH32DQBo5hwH0M6dOzVy5Mjg7VmzZkmSJk6cqKVLl+qZZ55RWVmZpk6dqtLSUg0dOlTr1q1TmzZt6q9rAECz5zHGGNtNfFkgEJDP57PdBm5RYWHO35Wurq52XBMdHe24Zs6cOY5rKisrHddI7p5Tly5dHNfExcU5rvn8888d17j9H2A3Pyc3F1K5Oe/c/mxnzJjhqs4Nv99/3c/1rV8FBwC4NRFAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGCF469jQNPm8Xgc17hdEN3NCr5u9uWmJjw83HGNJFVVVbmqc2ratGmOa4qLix3XVFRUOK6R3K1s7WbF6au/PflGuPnZulndW5LKysoc11y4cMFxjZtvgvZ6vY5rJHcrfLs5DjeCV0AAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAWLkTaSxlok1O3Com64XeDRKTeLTzbWoqKS9OijjzquSU5Odlyze/duxzURERGOayQpLi7Occ2ZM2cc15w9e9ZxTUJCguOamJgYxzWS+0VtnXKzsG9UVJSrffXo0cNxzd69e13tqy68AgIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK1iMtJE01iKhbhY1dFMjuVvw081xaMyFRSdNmuS4pmfPno5rioqKHNe4WYTTzSK4khQZGem45vjx445r3CwS6mYR3PLycsc1ktSmTRvHNY218LBbWVlZjmtYjBQA0KIQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwIpbejFSt4twuuFmsUE3ixq6WajRTU1jSk1NdVzzwAMPuNqXm0U4Dx065Limbdu2jmu8Xq/jmnbt2jmukaQLFy44rnFzjkdFRTmuccPtgraVlZWNsq+ysjLHNW7/3Q4ZMsRVXUPgFRAAwAoCCABgheMA2rJli+677z6lpqbK4/Fo9erVIfc/9thj8ng8IWPMmDH11S8AoIVwHEBlZWUaMGCAFi1adM05Y8aM0cmTJ4NjxYoVN9UkAKDlcXwRQnZ2trKzs687x+v1Kjk52XVTAICWr0E+A8rLy1NiYqJ69uypxx9/XGfOnLnm3MrKSgUCgZABAGj56j2AxowZo1/96lfasGGDFixYoM2bNys7O/ualybm5ubK5/MFR6dOneq7JQBAE1Tvfwf0yCOPBP+7X79+6t+/v7p166a8vDyNGjWqxvzZs2dr1qxZwduBQIAQAoBbQINfht21a1clJCQoPz+/1vu9Xq9iY2NDBgCg5WvwADp27JjOnDmjlJSUht4VAKAZcfwW3Pnz50NezRQWFmrv3r2Kj49XfHy85s2bpwkTJig5OVkFBQV65pln1L17d2VlZdVr4wCA5s1xAO3cuVMjR44M3r7y+c3EiRO1ePFi7du3T2+//bZKS0uVmpqq0aNH68UXX3S1jhUAoOXyGDcrCDagQCAgn8+nsLAwR4txul1sEFL79u1d1aWlpTmu6dWrl+MaN2/fullMU5IqKioc17hZWNTNZ50RERGOa9wsripJ0dHRjVLj5jmVlpY6rnH7+yE8PNxxjZuFRS9evOi4xs15J0k+n89xzY9//GNH86uqqnTgwAH5/f7rnuusBQcAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAAr6v0ruetLdXV1g+8jKSnJVZ2bVaAba3VhN6sfp6enO66RpKioKMc1blb9PX/+vOOasDB3/2/lZqVgN8f80qVLjmvcHO/y8nLHNZJUWVnpuKZ169aOa06ePOm4xs3PyM2xk6TPP//ccY2bVapvu+02xzVuVt2WpOTkZMc17dq1czT/Rs9vXgEBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBVNdjFSpzIzMx3XpKamutqXmwU1ExMTHde4WVDTzSKubp6PJJ07d85xjZuFGt0snujxeBzXSJLX63Vc42bBSjc/WzfHLjw83HGN5G6hSzfng9/vd1zj5t9SY3JzPrj5d+tmEVzJ3aKxThfPZTFSAECTRgABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArmuxipPfcc49atbrx9iZPnux4HwcOHHBcI0knT550XBMIBBzXuFlI8sKFC42yH7fcLFjpZvHEqqoqxzWSFBsb67jGzcKnbhaSdLNgZUREhOMayd0CsElJSY5r+vTp47jGzXNqzHPczUKuUVFRjmsqKioc10ju+jt16pSj+Td6rvIKCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsaLKLke7atcvRIo9f+cpXHO+jX79+jmskaciQIa7qnLp06ZLjGjeLfZ49e9Zxjds6v9/vuMbNYqRuFgiVpHbt2jmu6dmzp+MaN4tPulko1RjjuEaSBgwY4Lhm3759jmsOHz7suCYzM9NxjdfrdVwjuT9+Trn5t378+HFX+3KzMHLbtm0dzb/RxYB5BQQAsIIAAgBY4SiAcnNzdffddysmJkaJiYkaN26cDh48GDKnoqJCOTk5ateundq2basJEyaopKSkXpsGADR/jgJo8+bNysnJ0bZt27R+/XpdvHhRo0ePDvmCo5kzZ+qjjz7S+++/r82bN+vEiRN64IEH6r1xAEDz5ugihHXr1oXcXrp0qRITE7Vr1y4NHz5cfr9f//Ef/6Hly5frnnvukSQtWbJEd9xxh7Zt2+bqQgEAQMt0U58BXbmiKT4+XtLlK9cuXrwYcpVKr1691LlzZ23durXWx6isrFQgEAgZAICWz3UAVVdXa8aMGRoyZIj69u0rSSouLlbr1q0VFxcXMjcpKUnFxcW1Pk5ubq58Pl9wdOrUyW1LAIBmxHUA5eTkaP/+/XrvvfduqoHZs2fL7/cHR1FR0U09HgCgeXD1h6jTp0/X2rVrtWXLFnXs2DG4PTk5WRcuXFBpaWnIq6CSkhIlJyfX+lher9f1H4kBAJovR6+AjDGaPn26Vq1apY0bNyo9PT3k/oEDByoiIkIbNmwIbjt48KCOHj2qwYMH10/HAIAWwdEroJycHC1fvlxr1qxRTExM8HMdn8+nyMhI+Xw+TZ48WbNmzVJ8fLxiY2P1ve99T4MHD+YKOABACEcBtHjxYknSiBEjQrYvWbJEjz32mCTplVdeUVhYmCZMmKDKykplZWXpl7/8Zb00CwBoOTymsVbbu0GBQEA+n892G9fldGE+ScrIyHBcc/vttzuu+epXv+q4JjEx0XGN5G5xzOjoaMc1bhYWdXtaV1dXO65xsyjrgQMHHNesX7/ecc0f/vAHxzXS5RVNmqrf/va3jms6d+7sal+nT592XONmQWA3NW4WMJUu/+mLU0899ZSj+cYYlZeXy+/3X/f3BGvBAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwApWwwYANAhWwwYANEkEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBWOAig3N1d33323YmJilJiYqHHjxungwYMhc0aMGCGPxxMypk2bVq9NAwCaP0cBtHnzZuXk5Gjbtm1av369Ll68qNGjR6usrCxk3pQpU3Ty5MngWLhwYb02DQBo/lo5mbxu3bqQ20uXLlViYqJ27dql4cOHB7dHRUUpOTm5fjoEALRIN/UZkN/vlyTFx8eHbF+2bJkSEhLUt29fzZ49W+Xl5dd8jMrKSgUCgZABALgFGJeqqqrM2LFjzZAhQ0K2v/HGG2bdunVm37595t133zUdOnQw48ePv+bjzJ0710hiMBgMRgsbfr//ujniOoCmTZtm0tLSTFFR0XXnbdiwwUgy+fn5td5fUVFh/H5/cBQVFVk/aAwGg8G4+VFXADn6DOiK6dOna+3atdqyZYs6dux43bkZGRmSpPz8fHXr1q3G/V6vV16v100bAIBmzFEAGWP0ve99T6tWrVJeXp7S09PrrNm7d68kKSUlxVWDAICWyVEA5eTkaPny5VqzZo1iYmJUXFwsSfL5fIqMjFRBQYGWL1+ub3zjG2rXrp327dunmTNnavjw4erfv3+DPAEAQDPl5HMfXeN9viVLlhhjjDl69KgZPny4iY+PN16v13Tv3t08/fTTdb4P+GV+v9/6+5YMBoPBuPlR1+9+z/8FS5MRCATk8/lstwEAuEl+v1+xsbHXvJ+14AAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVjS5ADLG2G4BAFAP6vp93uQC6Ny5c7ZbAADUg7p+n3tME3vJUV1drRMnTigmJkYejyfkvkAgoE6dOqmoqEixsbGWOrSP43AZx+EyjsNlHIfLmsJxMMbo3LlzSk1NVVjYtV/ntGrEnm5IWFiYOnbseN05sbGxt/QJdgXH4TKOw2Uch8s4DpfZPg4+n6/OOU3uLTgAwK2BAAIAWNGsAsjr9Wru3Lnyer22W7GK43AZx+EyjsNlHIfLmtNxaHIXIQAAbg3N6hUQAKDlIIAAAFYQQAAAKwggAIAVBBAAwIpmE0CLFi1Sly5d1KZNG2VkZGjHjh22W2p0L7zwgjweT8jo1auX7bYa3JYtW3TfffcpNTVVHo9Hq1evDrnfGKM5c+YoJSVFkZGRyszM1KFDh+w024DqOg6PPfZYjfNjzJgxdpptILm5ubr77rsVExOjxMREjRs3TgcPHgyZU1FRoZycHLVr105t27bVhAkTVFJSYqnjhnEjx2HEiBE1zodp06ZZ6rh2zSKAfv3rX2vWrFmaO3eudu/erQEDBigrK0unTp2y3Vqj69Onj06ePBkcn3zyie2WGlxZWZkGDBigRYsW1Xr/woUL9dprr+n111/X9u3bFR0draysLFVUVDRypw2rruMgSWPGjAk5P1asWNGIHTa8zZs3KycnR9u2bdP69et18eJFjR49WmVlZcE5M2fO1EcffaT3339fmzdv1okTJ/TAAw9Y7Lr+3chxkKQpU6aEnA8LFy601PE1mGZg0KBBJicnJ3i7qqrKpKammtzcXItdNb65c+eaAQMG2G7DKklm1apVwdvV1dUmOTnZ/OQnPwluKy0tNV6v16xYscJCh43j6uNgjDETJ040999/v5V+bDl16pSRZDZv3myMufyzj4iIMO+//35wzt/+9jcjyWzdutVWmw3u6uNgjDFf+9rXzJNPPmmvqRvQ5F8BXbhwQbt27VJmZmZwW1hYmDIzM7V161aLndlx6NAhpaamqmvXrvr2t7+to0eP2m7JqsLCQhUXF4ecHz6fTxkZGbfk+ZGXl6fExET17NlTjz/+uM6cOWO7pQbl9/slSfHx8ZKkXbt26eLFiyHnQ69evdS5c+cWfT5cfRyuWLZsmRISEtS3b1/Nnj1b5eXlNtq7pia3GvbVTp8+raqqKiUlJYVsT0pK0oEDByx1ZUdGRoaWLl2qnj176uTJk5o3b56GDRum/fv3KyYmxnZ7VhQXF0tSrefHlftuFWPGjNEDDzyg9PR0FRQU6N/+7d+UnZ2trVu3Kjw83HZ79a66ulozZszQkCFD1LdvX0mXz4fWrVsrLi4uZG5LPh9qOw6S9K1vfUtpaWlKTU3Vvn379Oyzz+rgwYP68MMPLXYbqskHEP5fdnZ28L/79++vjIwMpaWl6Te/+Y0mT55ssTM0BY888kjwv/v166f+/furW7duysvL06hRoyx21jBycnK0f//+W+Jz0Ou51nGYOnVq8L/79eunlJQUjRo1SgUFBerWrVtjt1mrJv8WXEJCgsLDw2tcxVJSUqLk5GRLXTUNcXFxuv3225Wfn2+7FWuunAOcHzV17dpVCQkJLfL8mD59utauXatNmzaFfH9YcnKyLly4oNLS0pD5LfV8uNZxqE1GRoYkNanzockHUOvWrTVw4EBt2LAhuK26ulobNmzQ4MGDLXZm3/nz51VQUKCUlBTbrViTnp6u5OTkkPMjEAho+/btt/z5cezYMZ05c6ZFnR/GGE2fPl2rVq3Sxo0blZ6eHnL/wIEDFREREXI+HDx4UEePHm1R50Ndx6E2e/fulaSmdT7YvgriRrz33nvG6/WapUuXmr/+9a9m6tSpJi4uzhQXF9turVH94Ac/MHl5eaawsNB8+umnJjMz0yQkJJhTp07Zbq1BnTt3zuzZs8fs2bPHSDIvv/yy2bNnjzly5IgxxpiXXnrJxMXFmTVr1ph9+/aZ+++/36Snp5svvvjCcuf163rH4dy5c+app54yW7duNYWFhebjjz82//iP/2h69OhhKioqbLdebx5//HHj8/lMXl6eOXnyZHCUl5cH50ybNs107tzZbNy40ezcudMMHjzYDB482GLX9a+u45Cfn2/mz59vdu7caQoLC82aNWtM165dzfDhwy13HqpZBJAxxvziF78wnTt3Nq1btzaDBg0y27Zts91So3v44YdNSkqKad26tenQoYN5+OGHTX5+vu22GtymTZuMpBpj4sSJxpjLl2I///zzJikpyXi9XjNq1Chz8OBBu003gOsdh/LycjN69GjTvn17ExERYdLS0syUKVNa3P+k1fb8JZklS5YE53zxxRfmiSeeMLfddpuJiooy48ePNydPnrTXdAOo6zgcPXrUDB8+3MTHxxuv12u6d+9unn76aeP3++02fhW+DwgAYEWT/wwIANAyEUAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFf8LsGKa/ERlvdoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato da imagem: torch.Size([1, 28, 28])\n",
      "Rótulo: 9\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = training_data.classes\n",
    "image, label = test_data[0]\n",
    "\n",
    "# O tensor da imagem precisa ter a dimensão extra do canal de cor removida\n",
    "# Antes de ser exibida com matplotlib\n",
    "# A função .squeeze() faz isso\n",
    "image_to_show = image.squeeze()\n",
    "\n",
    "# Plotar a imagem\n",
    "plt.imshow(image_to_show, cmap=\"gray\")\n",
    "plt.title(f\"Label: {class_names[label]}\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimir o formato do tensor\n",
    "print(f\"Formato da imagem: {image.shape}\")\n",
    "print(f\"Rótulo: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
